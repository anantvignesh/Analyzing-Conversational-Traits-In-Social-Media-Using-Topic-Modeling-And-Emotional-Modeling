{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time =  03_25_20__11_57\n"
     ]
    }
   ],
   "source": [
    "#Import Dependencies\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import tweepy\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "import csv\n",
    "import multiprocessing\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Import the necessary package to process data in JSON format\n",
    "try:\n",
    "    import json\n",
    "except ImportError:\n",
    "    import simplejson as json\n",
    "\n",
    "#Get system time for the current run\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%m_%d_%y__%H_%M\")\n",
    "print(\"Current Time = \", current_time)\n",
    "\n",
    "#Function to flatten Json\n",
    "def flatten_json(nested_json):\n",
    "    #print(\"Flattening the Json data for processing convenience...\")\n",
    "    out = {}\n",
    "    def flatten(x, name=''):\n",
    "        if type(x) is dict:\n",
    "            for a in x:\n",
    "                flatten(x[a], name + a + '_')\n",
    "        elif type(x) is list:\n",
    "            i = 0\n",
    "            for a in x:\n",
    "                flatten(a, name + str(i) + '_')\n",
    "                i += 1\n",
    "        else:\n",
    "            out[name[:-1]] = x\n",
    "    flatten(nested_json)\n",
    "    #print(\"Flattening completed...\")\n",
    "    return out\n",
    "\n",
    "#Twitter Developer Access Tokens\n",
    "access_token = \"846302774-pPB0TfVkUWOO4aEr8hKNlKupkog1g1VFPnho1Td3\"\n",
    "access_token_secret = \"IUafuVm1YOk3S3hIflkUPxbI3Zb6pQubm2vseeBIRAx79\"\n",
    "consumer_key = \"uAMKZaMyqwAan03Cd5ZJpL56A\"\n",
    "consumer_secret = \"o9Q5OuYx6imBUcYvEIi8MVQ9WdSuCkCGIT9ieA0YNTJJZMBleL\"\n",
    "\n",
    "#Output Listener\n",
    "class StdOutListener(StreamListener):\n",
    "    def on_data(self, data):\n",
    "        #print(data)\n",
    "        dictList.append(flatten_json(json.loads(data)))\n",
    "        return True\n",
    "    def on_error(self, status):\n",
    "        print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to stream tweets for Politics from twitter... Task Starting Time: 03/25/20 11:57\n",
      "Current size of the data collected: 0\n",
      "Twitter Data Collection Inturrupted! Total Tweets Collected: 10754\n",
      "Task Ending Time: 03/25/20 12:23\n",
      "\n",
      "Converting JSON list to dataframe...03/25/20 12:23\n",
      "Task Ending Time: 03/25/20 12:23\n",
      "Creating a dataframe with only required columns from the streamed data... Task Starting Time: 03/25/20 12:23\n",
      "Task Ending Time: 03/25/20 12:23\n",
      "Creating CSV with the data...\n",
      "Created CSV with the data!\n",
      "-------------------------------------------------------\n",
      "\n",
      "Clearing previously streamed data...\n",
      "Starting to stream tweets for Corona from twitter... Task Starting Time: 03/25/20 12:23\n",
      "Current size of the data collected: 0\n",
      "Twitter Data Collection Inturrupted! Total Tweets Collected: 393\n",
      "Task Ending Time: 03/25/20 12:24\n",
      "\n",
      "Converting JSON list to dataframe...03/25/20 12:24\n",
      "Task Ending Time: 03/25/20 12:24\n",
      "Creating a dataframe with only required columns from the streamed data... Task Starting Time: 03/25/20 12:24\n",
      "Task Ending Time: 03/25/20 12:24\n",
      "Creating CSV with the data...\n",
      "Created CSV with the data!\n",
      "-------------------------------------------------------\n",
      "\n",
      "Clearing previously streamed data...\n",
      "Starting to stream tweets for Sports from twitter... Task Starting Time: 03/25/20 12:24\n",
      "Current size of the data collected: 0\n",
      "Twitter Data Collection Inturrupted! Total Tweets Collected: 23351\n",
      "Task Ending Time: 03/25/20 14:06\n",
      "\n",
      "Converting JSON list to dataframe...03/25/20 14:06\n",
      "Task Ending Time: 03/25/20 14:06\n",
      "Creating a dataframe with only required columns from the streamed data... Task Starting Time: 03/25/20 14:06\n",
      "Task Ending Time: 03/25/20 14:06\n",
      "Creating CSV with the data...\n",
      "Created CSV with the data!\n",
      "-------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Global Variables\n",
    "dictList = []\n",
    "\n",
    "#Main Function\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #Streaming API\n",
    "    l = StdOutListener()\n",
    "    \n",
    "    #This handles Twitter authetification and the connection to Twitter\n",
    "    auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    topics = ['Politics', 'Corona', 'Sports']\n",
    "    #topics = ['Politics', 'Corona', 'Sports', 'Nutrition', 'Technology']\n",
    "    for topic in topics:\n",
    "        if len(dictList) > 0:\n",
    "            print(\"Clearing previously streamed data...\")\n",
    "            dictList = []\n",
    "\n",
    "        try:\n",
    "            print(\"Starting to stream tweets for \"+topic+\" from twitter... Task Starting Time: \" + datetime.now().strftime(\"%m/%d/%y %H:%M\"))\n",
    "            print((\"Current size of the data collected: %d\")%(len(dictList)))\n",
    "            stream = Stream(auth, l)\n",
    "\n",
    "            #Filter Tweets to specified words\n",
    "            iterator = stream.filter(track=[topic])\n",
    "        except:\n",
    "            print((\"Twitter Data Collection Inturrupted! Total Tweets Collected: %d\")%(len(dictList)))\n",
    "            print(\"Task Ending Time: \" + datetime.now().strftime(\"%m/%d/%y %H:%M\") + \"\\n\")\n",
    "            \n",
    "        #Convert JSON list to dataframe\n",
    "        print(\"Converting JSON list to dataframe...\" + datetime.now().strftime(\"%m/%d/%y %H:%M\"))\n",
    "        dfItem = pd.DataFrame.from_records(dictList)\n",
    "        print(\"Task Ending Time: \" + datetime.now().strftime(\"%m/%d/%y %H:%M\"))\n",
    "        \n",
    "        #Get all column names\n",
    "        allCols = list(dfItem.columns.values)\n",
    "\n",
    "        #Required Columns from the stream\n",
    "        cols = ['created_at', 'id_str', 'text', 'user_name', 'user_screen_name',  'user_location', 'retweeted_status_text', \n",
    "                'extended_tweet_full_text', 'retweeted_status_extended_tweet_full_text', 'lang']\n",
    "\n",
    "        #Drop unwanted columns from the dataframe\n",
    "        print(\"Creating a dataframe with only required columns from the streamed data... Task Starting Time: \" + datetime.now().strftime(\"%m/%d/%y %H:%M\"))\n",
    "        dropCols = []\n",
    "        for colName in allCols:\n",
    "            if colName not in cols:\n",
    "                dropCols.append(colName)\n",
    "\n",
    "        dfItem.drop(dropCols, axis=1, inplace=True)\n",
    "        print(\"Task Ending Time: \" + datetime.now().strftime(\"%m/%d/%y %H:%M\"))\n",
    "\n",
    "        #Add a dummy string prefix to all the values of the column 'id_str' for computational convenience\n",
    "        '''print(\"Adding a dummy string prefix to all the values of the column id_str for computational convenience... Task Starting Time: \" + datetime.now().strftime(\"%m/%d/%y %H:%M\"))\n",
    "        for i in range(len(dfItem)):\n",
    "            dfItem['id_str'][i] = str(dfItem['id_str'][i]) + 'ABC'\n",
    "            dfItem['user_id_str'][i] = str(dfItem['user_id_str'][i]) + 'ABC'\n",
    "            dfItem['in_reply_to_status_id_str'][i] = str(dfItem['in_reply_to_status_id_str'][i]) + 'ABC'\n",
    "            dfItem['in_reply_to_user_id_str'][i] = str(dfItem['in_reply_to_user_id_str'][i]) + 'ABC'\n",
    "        print(\"Task Ending Time: \" + datetime.now().strftime(\"%m/%d/%y %H:%M\"))'''\n",
    "\n",
    "        #Write dataframe to CSV\n",
    "        print(\"Creating CSV with the data...\")\n",
    "        dfItem.to_csv(\"D:/MS COMPUTER SCIENCE/MS PROJECTS/MAIN PROJECT/DataCollection/Twitter/\"+topic+\"/TwitterData_\"+topic+\"_\"+current_time+\".csv\", index=False)\n",
    "        print(\"Created CSV with the data!\")\n",
    "        print(\"-------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unwanted columns from the dataframe\n",
    "print(\"Creating a dataframe with only required columns from the streamed data... Task Starting Time: \" + datetime.now().strftime(\"%m/%d/%y %H:%M\"))\n",
    "dropCols = []\n",
    "for colName in allCols:\n",
    "    if colName not in cols:\n",
    "        dropCols.append(colName)\n",
    "\n",
    "dfItem.drop(dropCols, axis=1, inplace=True)\n",
    "print(\"Task Ending Time: \" + datetime.now().strftime(\"%m/%d/%y %H:%M\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41797\n"
     ]
    }
   ],
   "source": [
    "print(len(dfItem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert JSON list to dataframe\n",
    "print(\"Converting JSON list to dataframe...\" + datetime.now().strftime(\"%m/%j/%y %H:%M\"))\n",
    "dfItem = pd.DataFrame.from_records(dictList)\n",
    "print(\"Task Ending Time: \" + datetime.now().strftime(\"%m/%j/%y %H:%M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(dfItem['reply_count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Convert JSON list to dataframe\n",
    "    print(\"Converting JSON list to dataframe...\" + datetime.now().strftime(\"%m/%j/%y %H:%M\"))\n",
    "    dfItem = pd.DataFrame.from_records(dictList)\n",
    "    print(\"Task Ending Time: \" + datetime.now().strftime(\"%m/%j/%y %H:%M\"))\n",
    "\n",
    "    #Get all column names\n",
    "    allCols = list(dfItem.columns.values)\n",
    "\n",
    "    #Required Columns from the stream\n",
    "    cols = ['created_at', 'id_str', 'text', 'user_id_str', 'user_name', 'user_screen_name',  'user_verified', 'user_followers_count', 'user_friends_count', \n",
    "            'user_favourites_count', 'user_statuses_count', 'in_reply_to_status_id_str', 'in_reply_to_user_id_str',  'in_reply_to_screen_name', \n",
    "            'extended_tweet_full_text', 'retweeted_status_extended_tweet_full_text', 'quote_count', 'reply_count', 'retweet_count', 'favorite_count', \n",
    "            'favorited', 'retweeted', 'filter_level', 'lang']\n",
    "\n",
    "    #Drop unwanted columns from the dataframe\n",
    "    print(\"Creating a dataframe with only required columns from the streamed data... Task Starting Time: \" + datetime.now().strftime(\"%m/%j/%y %H:%M\"))\n",
    "    dropCols = []\n",
    "    for colName in allCols:\n",
    "        if colName not in cols:\n",
    "            dropCols.append(colName)\n",
    "\n",
    "    dfItem.drop(dropCols, axis=1, inplace=True)\n",
    "    print(\"Task Ending Time: \" + datetime.now().strftime(\"%m/%j/%y %H:%M\"))\n",
    "\n",
    "    #Add a dummy string prefix to all the values of the column 'id_str' for computational convenience\n",
    "    print(\"Adding a dummy string prefix to all the values of the column id_str for computational convenience... Task Starting Time: \" + datetime.now().strftime(\"%m/%j/%y %H:%M\"))\n",
    "    for i in range(len(dfItem)):\n",
    "        dfItem['id_str'][i] = str(dfItem['id_str'][i]) + 'ABC'\n",
    "        dfItem['user_id_str'][i] = str(dfItem['user_id_str'][i]) + 'ABC'\n",
    "        dfItem['in_reply_to_status_id_str'][i] = str(dfItem['in_reply_to_status_id_str'][i]) + 'ABC'\n",
    "        dfItem['in_reply_to_user_id_str'][i] = str(dfItem['in_reply_to_user_id_str'][i]) + 'ABC'\n",
    "    print(\"Task Ending Time: \" + datetime.now().strftime(\"%m/%j/%y %H:%M\"))\n",
    "\n",
    "    #Write dataframe to CSV\n",
    "    print(\"Creating CSV with the data...\")\n",
    "    dfItem.to_csv(\"D:/MS COMPUTER SCIENCE/MS PROJECTS/MAIN PROJECT/DataCollection/Twitter/Test/TwitterData_\"+current_time+\".csv\", index=False)\n",
    "    print(\"Created CSV with the data...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
